{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project you'll dig into a large amount of text and apply most of what you've covered in this unit and in the course so far.\n",
    "\n",
    "First, pick a set of texts. This can be either a series of novels, chapters, or articles. Anything you'd like. It just has to have multiple entries of varying characteristics. At least 100 should be good. There should also be at least 10 different authors, but try to keep the texts related (either all on the same topic of from the same branch of literature - something to make classification a bit more difficult than obviously different subjects).\n",
    "\n",
    "This capstone can be an extension of your NLP challenge if you wish to use the same corpus. If you found problems with that data set that limited your analysis, however, it may be worth using what you learned to choose a new corpus. Reserve 25% of your corpus as a test set.\n",
    "\n",
    "The first technique is to create a series of clusters. Try several techniques and pick the one you think best represents your data. Make sure there is a narrative and reasoning around why you have chosen the given clusters. Are authors consistently grouped into the same cluster?\n",
    "\n",
    "Next, perform some unsupervised feature generation and selection using the techniques covered in this unit and elsewhere in the course. Using those features then build models to attempt to classify your texts by author. Try different permutations of unsupervised and supervised techniques to see which combinations have the best performance.\n",
    "\n",
    "Lastly return to your holdout group. Does your clustering on those members perform as you'd expect? Have your clusters remained stable or changed dramatically? What about your model? Is it's performance consistent?\n",
    "\n",
    "If there is a divergence in the relative stability of your model and your clusters, delve into why.\n",
    "\n",
    "Your end result should be a write up of how clustering and modeling compare for classifying your texts. What are the advantages of each? Why would you want to use one over the other? Approximately 3-5 pages is a good length for your write up, and remember to include visuals to help tell your story!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset.\n",
    "news = pd.read_csv('C:\\\\Users\\\\kenne\\\\Desktop\\\\uci-news-aggregator.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using a News Aggregator Dataset which contains headlines and categories of over 400,000 news stories scraped from the web between March 10, 2014 to August 10, 2014.\n",
    "\n",
    "News categories included in this dataset include business, science and technology, entertainment and health.\n",
    "\n",
    "The columns included in this dataset are:\n",
    "\n",
    "ID : the numeric ID of the article\n",
    "TITLE : the headline of the article\n",
    "URL : the URL of the article\n",
    "PUBLISHER : the publisher of the article\n",
    "CATEGORY : the category of the news item; one of: -- b : business -- t : science and technology -- e : entertainment -- m : health\n",
    "STORY : alphanumeric ID of the news story that the article discusses\n",
    "HOSTNAME : hostname where the article was posted\n",
    "TIMESTAMP : approximate timestamp of the article's publication, given in Unix time (seconds since midnight on Jan 1, 1970)\n",
    "\n",
    "This dataset comes from the UCI Machine Learning Repository. Any publications that use this data should cite the repository as follows:\n",
    "\n",
    "Lichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California,      School of Information and Computer Science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>URL</th>\n",
       "      <th>PUBLISHER</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>STORY</th>\n",
       "      <th>HOSTNAME</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>422419.000000</td>\n",
       "      <td>422419</td>\n",
       "      <td>422419</td>\n",
       "      <td>422417</td>\n",
       "      <td>422419</td>\n",
       "      <td>422419</td>\n",
       "      <td>422419</td>\n",
       "      <td>4.224190e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>406453</td>\n",
       "      <td>422223</td>\n",
       "      <td>10985</td>\n",
       "      <td>4</td>\n",
       "      <td>7230</td>\n",
       "      <td>11236</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>The article requested cannot be found! Please ...</td>\n",
       "      <td>http://www.japantimes.co.jp/news/2014/04/18/wo...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>e</td>\n",
       "      <td>dubwcJArLL_qAKML5LGPLiunKzNLM</td>\n",
       "      <td>in.reuters.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>3902</td>\n",
       "      <td>152469</td>\n",
       "      <td>450</td>\n",
       "      <td>2877</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>211536.764594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.400445e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>122102.839707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.733062e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.394470e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>105801.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.397350e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>211655.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.399990e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>317273.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.403770e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>422937.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.409230e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID                                              TITLE  \\\n",
       "count   422419.000000                                             422419   \n",
       "unique            NaN                                             406453   \n",
       "top               NaN  The article requested cannot be found! Please ...   \n",
       "freq              NaN                                                145   \n",
       "mean    211536.764594                                                NaN   \n",
       "std     122102.839707                                                NaN   \n",
       "min          1.000000                                                NaN   \n",
       "25%     105801.500000                                                NaN   \n",
       "50%     211655.000000                                                NaN   \n",
       "75%     317273.500000                                                NaN   \n",
       "max     422937.000000                                                NaN   \n",
       "\n",
       "                                                      URL PUBLISHER CATEGORY  \\\n",
       "count                                              422419    422417   422419   \n",
       "unique                                             422223     10985        4   \n",
       "top     http://www.japantimes.co.jp/news/2014/04/18/wo...   Reuters        e   \n",
       "freq                                                    5      3902   152469   \n",
       "mean                                                  NaN       NaN      NaN   \n",
       "std                                                   NaN       NaN      NaN   \n",
       "min                                                   NaN       NaN      NaN   \n",
       "25%                                                   NaN       NaN      NaN   \n",
       "50%                                                   NaN       NaN      NaN   \n",
       "75%                                                   NaN       NaN      NaN   \n",
       "max                                                   NaN       NaN      NaN   \n",
       "\n",
       "                                STORY        HOSTNAME     TIMESTAMP  \n",
       "count                          422419          422419  4.224190e+05  \n",
       "unique                           7230           11236           NaN  \n",
       "top     dubwcJArLL_qAKML5LGPLiunKzNLM  in.reuters.com           NaN  \n",
       "freq                              450            2877           NaN  \n",
       "mean                              NaN             NaN  1.400445e+12  \n",
       "std                               NaN             NaN  3.733062e+09  \n",
       "min                               NaN             NaN  1.394470e+12  \n",
       "25%                               NaN             NaN  1.397350e+12  \n",
       "50%                               NaN             NaN  1.399990e+12  \n",
       "75%                               NaN             NaN  1.403770e+12  \n",
       "max                               NaN             NaN  1.409230e+12  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           0\n",
       "TITLE        0\n",
       "URL          0\n",
       "PUBLISHER    2\n",
       "CATEGORY     0\n",
       "STORY        0\n",
       "HOSTNAME     0\n",
       "TIMESTAMP    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 422419 entries, 0 to 422418\n",
      "Data columns (total 8 columns):\n",
      "ID           422419 non-null int64\n",
      "TITLE        422419 non-null object\n",
      "URL          422419 non-null object\n",
      "PUBLISHER    422417 non-null object\n",
      "CATEGORY     422419 non-null object\n",
      "STORY        422419 non-null object\n",
      "HOSTNAME     422419 non-null object\n",
      "TIMESTAMP    422419 non-null float64\n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 25.8+ MB\n"
     ]
    }
   ],
   "source": [
    "news.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>URL</th>\n",
       "      <th>PUBLISHER</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>STORY</th>\n",
       "      <th>HOSTNAME</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Fed official says weak data caused by weather,...</td>\n",
       "      <td>http://www.latimes.com/business/money/la-fi-mo...</td>\n",
       "      <td>Los Angeles Times</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.latimes.com</td>\n",
       "      <td>1.394470e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
       "      <td>http://www.livemint.com/Politics/H2EvwJSK2VE6O...</td>\n",
       "      <td>Livemint</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.livemint.com</td>\n",
       "      <td>1.394470e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>US open: Stocks fall after Fed official hints ...</td>\n",
       "      <td>http://www.ifamagazine.com/news/us-open-stocks...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.ifamagazine.com</td>\n",
       "      <td>1.394470e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Fed risks falling 'behind the curve', Charles ...</td>\n",
       "      <td>http://www.ifamagazine.com/news/fed-risks-fall...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.ifamagazine.com</td>\n",
       "      <td>1.394470e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n",
       "      <td>http://www.moneynews.com/Economy/federal-reser...</td>\n",
       "      <td>Moneynews</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.moneynews.com</td>\n",
       "      <td>1.394470e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              TITLE  \\\n",
       "0   1  Fed official says weak data caused by weather,...   \n",
       "1   2  Fed's Charles Plosser sees high bar for change...   \n",
       "2   3  US open: Stocks fall after Fed official hints ...   \n",
       "3   4  Fed risks falling 'behind the curve', Charles ...   \n",
       "4   5  Fed's Plosser: Nasty Weather Has Curbed Job Gr...   \n",
       "\n",
       "                                                 URL          PUBLISHER  \\\n",
       "0  http://www.latimes.com/business/money/la-fi-mo...  Los Angeles Times   \n",
       "1  http://www.livemint.com/Politics/H2EvwJSK2VE6O...           Livemint   \n",
       "2  http://www.ifamagazine.com/news/us-open-stocks...       IFA Magazine   \n",
       "3  http://www.ifamagazine.com/news/fed-risks-fall...       IFA Magazine   \n",
       "4  http://www.moneynews.com/Economy/federal-reser...          Moneynews   \n",
       "\n",
       "  CATEGORY                          STORY             HOSTNAME     TIMESTAMP  \n",
       "0        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM      www.latimes.com  1.394470e+12  \n",
       "1        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM     www.livemint.com  1.394470e+12  \n",
       "2        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1.394470e+12  \n",
       "3        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1.394470e+12  \n",
       "4        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM    www.moneynews.com  1.394470e+12  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "Research Question: Can we predict the cateogry of a news article (business, science and technology, entertainment, health) given only its headline?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to remove all columns except for TITLE and CATEGORY for the purposes of our research.\n",
    "news.drop(['ID', 'URL', 'PUBLISHER', 'STORY', 'HOSTNAME', 'TIMESTAMP'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fed official says weak data caused by weather,...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US open: Stocks fall after Fed official hints ...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fed risks falling 'behind the curve', Charles ...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE CATEGORY\n",
       "0  Fed official says weak data caused by weather,...        b\n",
       "1  Fed's Charles Plosser sees high bar for change...        b\n",
       "2  US open: Stocks fall after Fed official hints ...        b\n",
       "3  Fed risks falling 'behind the curve', Charles ...        b\n",
       "4  Fed's Plosser: Nasty Weather Has Curbed Job Gr...        b"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CATEGORY\n",
       "b    115967\n",
       "e    152469\n",
       "m     45639\n",
       "t    108344\n",
       "Name: TITLE, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.groupby('CATEGORY')['TITLE'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the 'm' category has significantly less samples and the 'e' category has considerably more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a sample of 1000 rows from each category to balance the samples.\n",
    "news_sample = news.groupby('CATEGORY').apply(lambda x: x.sample(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenne\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: 'CATEGORY' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CATEGORY\n",
       "b    1000\n",
       "e    1000\n",
       "m    1000\n",
       "t    1000\n",
       "Name: TITLE, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_sample.groupby('CATEGORY')['TITLE'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4000</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3994</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Malaysia Moves to Contain Deadly MERS Virus</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              TITLE CATEGORY\n",
       "count                                          4000     4000\n",
       "unique                                         3994        4\n",
       "top     Malaysia Moves to Contain Deadly MERS Virus        m\n",
       "freq                                              2     1000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CATEGORY</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">t</th>\n",
       "      <th>152576</th>\n",
       "      <td>Think Samsung's Fingerprint Scanner Is Foolpro...</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122500</th>\n",
       "      <td>VW Applies Subtle Updates to 2015 Jetta, Gives...</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322723</th>\n",
       "      <td>Internet TV marches on in wake of Aereo decision</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213930</th>\n",
       "      <td>Google I/O 2014 schedule is now available</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277776</th>\n",
       "      <td>NASA uses laser to beam video from space</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             TITLE CATEGORY\n",
       "CATEGORY                                                                   \n",
       "t        152576  Think Samsung's Fingerprint Scanner Is Foolpro...        t\n",
       "         122500  VW Applies Subtle Updates to 2015 Jetta, Gives...        t\n",
       "         322723   Internet TV marches on in wake of Aereo decision        t\n",
       "         213930          Google I/O 2014 schedule is now available        t\n",
       "         277776           NASA uses laser to beam video from space        t"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_sample.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 4000 entries, (b, 334392) to (t, 277776)\n",
      "Data columns (total 2 columns):\n",
      "TITLE       4000 non-null object\n",
      "CATEGORY    4000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 105.6+ KB\n"
     ]
    }
   ],
   "source": [
    "news_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to clean text.\n",
    "def text_cleaner(text):\n",
    "    \n",
    "    # spaCy does not recognize the double dash.\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    # Removing all numbers.\n",
    "    text = re.sub(r'\\d','',text)\n",
    "    # Removing all punctuations not word-internal.\n",
    "    text = re.sub('\\s\\W',' ',text)\n",
    "    text = re.sub('\\W\\s',' ',text)\n",
    "    # Making sure I didn't introduce any double spaces.\n",
    "    text = re.sub('\\s+',' ',text)\n",
    "    # Converting all text to lower case.\n",
    "    text = text.lower()\n",
    "    # Removing extra whitespace.\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # Placeholder to remove everything not a letter (for consideration).\n",
    "    #text = re.sub('[^a-zA-Z]',' ',text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CATEGORY</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">b</th>\n",
       "      <th>334392</th>\n",
       "      <td>full recap daniel bryan injury update and bo d...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125145</th>\n",
       "      <td>housing starts rise slightly in march</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9047</th>\n",
       "      <td>update ackman accuses herbalife of breaking la...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116163</th>\n",
       "      <td>tax day for those expecting a refund late pena...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309862</th>\n",
       "      <td>s.f to fight metered parking the hogging economy'</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             TITLE CATEGORY\n",
       "CATEGORY                                                                   \n",
       "b        334392  full recap daniel bryan injury update and bo d...        b\n",
       "         125145              housing starts rise slightly in march        b\n",
       "         9047    update ackman accuses herbalife of breaking la...        b\n",
       "         116163  tax day for those expecting a refund late pena...        b\n",
       "         309862  s.f to fight metered parking the hogging economy'        b"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning the data.\n",
    "news_sample['TITLE'] = news_sample.TITLE.map(lambda x: text_cleaner(str(x)))\n",
    "\n",
    "news_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 4000 entries, (b, 334392) to (t, 277776)\n",
      "Data columns (total 2 columns):\n",
      "TITLE       4000 non-null object\n",
      "CATEGORY    4000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 105.6+ KB\n"
     ]
    }
   ],
   "source": [
    "news_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the features and the outcome variables.\n",
    "X = news_sample['TITLE']\n",
    "y = news_sample['CATEGORY']\n",
    "\n",
    "# Splitting the data into train and test sets (reserving 25% of my corpus as a test set).\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Frequency Inverse Document Frequency (Tf-idf) vectorization translates human-readable language to computer usable numeric form and is fundamental for many unsupervised Natural Language Processing (NLP) tasks. Tf-idf will take into account how many times a particular word appears and captures the words used less frequently to generate a vector for each word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 3683\n",
      "Original sentence: skin cancer rates on the rise in canada\n",
      "Tf_idf vector: {'email': 0.4966881434531527, 'google': 0.29327234676946734, 'unveils': 0.43315123838080677, 'messages': 0.4826728826188848, 'tool': 0.4966881434531527}\n"
     ]
    }
   ],
   "source": [
    "# Tf-idf vecotrization to turn our headlines into vectors.\n",
    "vectorizer = TfidfVectorizer(max_df=0.5,               # Drops the words that appear in more than half the headlines.\n",
    "                             min_df=2,                 # Uses only words that appear twice.\n",
    "                             stop_words='english',     # Drops English stop words.\n",
    "                             lowercase=True,           # Converting everything to lower case (may be redundant).\n",
    "                             use_idf=True,             # Using inverse document frequencies in our weighting.\n",
    "                             norm=u'l2',               # Applies a correction factor so that longer and shorter headings are treated equally.\n",
    "                             smooth_idf=True           # Adds 1 to all document frequencie to prevent divide-by-zero errors.\n",
    "                            )\n",
    "\n",
    "# Applying the vectorizer.\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "print('Number of features: {}'.format(X_tfidf.get_shape()[1]))\n",
    "\n",
    "# Splitting into train and test sets (reserving 25% of my corpus as a test set).\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Reshape vectorizer to readable content\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr()\n",
    "\n",
    "# Number of headings.\n",
    "n = X_train_tfidf_csr.shape[0]\n",
    "\n",
    "# A list of dictionaries, one per heading.\n",
    "tfidf_bypara = [{} for _ in range(0,n)]\n",
    "\n",
    "# List of features.\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "# For each paragraph, lists the feature words and their tf-idf scores.\n",
    "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
    "    tfidf_bypara[i][terms[j]] = X_train_tfidf_csr[i, j]\n",
    "\n",
    "# Keep in mind that the log base 2 of 1 is 0, so a tf-idf score of 0 indicates that the word was present once in that sentence.\n",
    "print('Original sentence:', X_train[593])\n",
    "print('Tf_idf vector:', tfidf_bypara[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data.\n",
    "X_norm = normalize(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization is the process of breaking up text into individual meaninful pieces, such as words and punctuation. Note, we removed punctuations earlier because we believed they wouldn't provide much value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading spaCy's English module.\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scanning each row for tokens. Also capturing the length of each heading and identifying the different parts of speech.\n",
    "X_train_words = []\n",
    "\n",
    "for row in X_train:\n",
    "    row_doc = nlp(row)\n",
    "    heading_len = len(row_doc) \n",
    "    advs = 0\n",
    "    verb = 0\n",
    "    noun = 0\n",
    "    adj = 0\n",
    "    for token in row_doc:\n",
    "        if token.pos_ == 'ADV':\n",
    "            advs +=1\n",
    "        elif token.pos_ == 'VERB':\n",
    "            verb +=1\n",
    "        elif token.pos_ == 'NOUN':\n",
    "            noun +=1\n",
    "        elif token.pos_ == 'ADJ':\n",
    "            adj +=1\n",
    "\n",
    "    X_train_words.append([row_doc, advs, verb, noun, adj, heading_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new = y_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturing generated features in new dataframe with categories.\n",
    "news_bow = pd.DataFrame(data=X_train_words, columns=['BOW', 'ADV', 'VERB', 'NOUN', 'ADJ', 'heading_length'])\n",
    "\n",
    "news_bow = pd.concat([news_bow, y_train_new], ignore_index=False, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOW</th>\n",
       "      <th>ADV</th>\n",
       "      <th>VERB</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>heading_length</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(google, unveils, tool, to, encrypt, email, me...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(pharrell, williams, named, coach, ahead, of, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(current, mortgage, rates, at, hsbc, citizens,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(trade, -, ideas, navient, navi, is, today, 's...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(game, of, thrones, season, episode, recap, to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 BOW  ADV  VERB  NOUN  ADJ  \\\n",
       "0  (google, unveils, tool, to, encrypt, email, me...    1     1     4    0   \n",
       "1  (pharrell, williams, named, coach, ahead, of, ...    1     1     5    0   \n",
       "2  (current, mortgage, rates, at, hsbc, citizens,...    0     0     4    2   \n",
       "3  (trade, -, ideas, navient, navi, is, today, 's...    0     1     8    1   \n",
       "4  (game, of, thrones, season, episode, recap, to...    0     0     6    1   \n",
       "\n",
       "   heading_length CATEGORY  \n",
       "0               7        t  \n",
       "1              12        e  \n",
       "2               8        b  \n",
       "3              13        b  \n",
       "4               8        e  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOW</th>\n",
       "      <th>ADV</th>\n",
       "      <th>VERB</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>heading_length</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>(outlander, review, adventure, romance, and, k...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>(', an, act, of, war, ', north, korea, issues,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>(asian, shares, gain, as, chinese, manufacturi...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>(spacex, resupply, mission, set, for, flight, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>(samsung, releases, new, mini, galaxy, s)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    BOW  ADV  VERB  NOUN  ADJ  \\\n",
       "2995  (outlander, review, adventure, romance, and, k...    0     2     6    0   \n",
       "2996  (', an, act, of, war, ', north, korea, issues,...    0     1     7    2   \n",
       "2997  (asian, shares, gain, as, chinese, manufacturi...    0     2     2    2   \n",
       "2998  (spacex, resupply, mission, set, for, flight, ...    0     1     6    0   \n",
       "2999          (samsung, releases, new, mini, galaxy, s)    0     1     3    2   \n",
       "\n",
       "      heading_length CATEGORY  \n",
       "2995              13        e  \n",
       "2996              16        e  \n",
       "2997               7        b  \n",
       "2998               9        t  \n",
       "2999               6        t  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_bow.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Including the Tf-idf vectors created earlier.\n",
    "X_norm_df = pd.DataFrame(data=X_norm.toarray())\n",
    "news_tfidf_bow = pd.concat([news_bow, X_norm_df], ignore_index=False, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOW</th>\n",
       "      <th>ADV</th>\n",
       "      <th>VERB</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>heading_length</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>3673</th>\n",
       "      <th>3674</th>\n",
       "      <th>3675</th>\n",
       "      <th>3676</th>\n",
       "      <th>3677</th>\n",
       "      <th>3678</th>\n",
       "      <th>3679</th>\n",
       "      <th>3680</th>\n",
       "      <th>3681</th>\n",
       "      <th>3682</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(google, unveils, tool, to, encrypt, email, me...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>t</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(pharrell, williams, named, coach, ahead, of, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(current, mortgage, rates, at, hsbc, citizens,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(trade, -, ideas, navient, navi, is, today, 's...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(game, of, thrones, season, episode, recap, to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  3690 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 BOW  ADV  VERB  NOUN  ADJ  \\\n",
       "0  (google, unveils, tool, to, encrypt, email, me...    1     1     4    0   \n",
       "1  (pharrell, williams, named, coach, ahead, of, ...    1     1     5    0   \n",
       "2  (current, mortgage, rates, at, hsbc, citizens,...    0     0     4    2   \n",
       "3  (trade, -, ideas, navient, navi, is, today, 's...    0     1     8    1   \n",
       "4  (game, of, thrones, season, episode, recap, to...    0     0     6    1   \n",
       "\n",
       "   heading_length CATEGORY    0    1    2  ...   3673  3674  3675  3676  3677  \\\n",
       "0               7        t  0.0  0.0  0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "1              12        e  0.0  0.0  0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "2               8        b  0.0  0.0  0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "3              13        b  0.0  0.0  0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "4               8        e  0.0  0.0  0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   3678  3679  3680  3681  3682  \n",
       "0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 3690 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_tfidf_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOW</th>\n",
       "      <th>ADV</th>\n",
       "      <th>VERB</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>heading_length</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>3673</th>\n",
       "      <th>3674</th>\n",
       "      <th>3675</th>\n",
       "      <th>3676</th>\n",
       "      <th>3677</th>\n",
       "      <th>3678</th>\n",
       "      <th>3679</th>\n",
       "      <th>3680</th>\n",
       "      <th>3681</th>\n",
       "      <th>3682</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>(outlander, review, adventure, romance, and, k...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>(', an, act, of, war, ', north, korea, issues,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>(asian, shares, gain, as, chinese, manufacturi...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>(spacex, resupply, mission, set, for, flight, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>t</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>(samsung, releases, new, mini, galaxy, s)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>t</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  3690 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    BOW  ADV  VERB  NOUN  ADJ  \\\n",
       "2995  (outlander, review, adventure, romance, and, k...    0     2     6    0   \n",
       "2996  (', an, act, of, war, ', north, korea, issues,...    0     1     7    2   \n",
       "2997  (asian, shares, gain, as, chinese, manufacturi...    0     2     2    2   \n",
       "2998  (spacex, resupply, mission, set, for, flight, ...    0     1     6    0   \n",
       "2999          (samsung, releases, new, mini, galaxy, s)    0     1     3    2   \n",
       "\n",
       "      heading_length CATEGORY    0    1    2  ...   3673  3674  3675  3676  \\\n",
       "2995              13        e  0.0  0.0  0.0  ...    0.0   0.0   0.0   0.0   \n",
       "2996              16        e  0.0  0.0  0.0  ...    0.0   0.0   0.0   0.0   \n",
       "2997               7        b  0.0  0.0  0.0  ...    0.0   0.0   0.0   0.0   \n",
       "2998               9        t  0.0  0.0  0.0  ...    0.0   0.0   0.0   0.0   \n",
       "2999               6        t  0.0  0.0  0.0  ...    0.0   0.0   0.0   0.0   \n",
       "\n",
       "      3677  3678  3679  3680  3681  3682  \n",
       "2995   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2996   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2997   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2998   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2999   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 3690 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_tfidf_bow.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection.\n",
    "features = news_tfidf_bow.drop(['BOW', 'CATEGORY'], axis=1)\n",
    "\n",
    "# Categories.\n",
    "y2_train = news_tfidf_bow.CATEGORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there is a considerable number of features now, I will use k best with chi-squared to select the 400 best features.\n",
    "kbest = SelectKBest(chi2, k=400)\n",
    "\n",
    "X2_train = kbest.fit_transform(features, y2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means clustering method is used for grouping data into clusters of similar data points with similar differences. It uses a cost function called the inertia, and the algorithm tries to choose means (called centroids) that minimize the inertia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CATEGORY</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>88</td>\n",
       "      <td>245</td>\n",
       "      <td>225</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>190</td>\n",
       "      <td>196</td>\n",
       "      <td>144</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>91</td>\n",
       "      <td>257</td>\n",
       "      <td>247</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>127</td>\n",
       "      <td>283</td>\n",
       "      <td>178</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0       0    1    2    3\n",
       "CATEGORY                    \n",
       "b          88  245  225  175\n",
       "e         190  196  144  213\n",
       "m          91  257  247  164\n",
       "t         127  283  178  177"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will choose 4 clusters since we have labeled data with known classes (4), otherwise I would have chosen at random.\n",
    "kmeans = KMeans(n_clusters=4, init='k-means++', random_state=42)\n",
    "y_pred = kmeans.fit_predict(X2_train)\n",
    "\n",
    "pd.crosstab(y2_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Score: 0.009740383806655357\n",
      "Silhouette Score: 0.22921928734290828\n"
     ]
    }
   ],
   "source": [
    "# Displaying adjusted rand index and silhouette coefficient.\n",
    "print('Adjusted Rand Score: {}'.format(adjusted_rand_score(y2_train, y_pred)))\n",
    "print('Silhouette Score: {}'.format(silhouette_score(X2_train, y_pred, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Adjusted Rand Score indicates that the K-Means clustering solution is close to perfect randomness. A different algorithim would do better!\n",
    "\n",
    "The Silhouette Score indicates that the K-Means clustering solution is somewhat reliable at clustering datapoints that are more similar to one another than they are to datapoints in other clusters. This is good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than reducing dimensions using PCA on the data, I am going to use MiniBatchKMeans in sklearn, which randomly samples subsets of the training data in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CATEGORY</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>209</td>\n",
       "      <td>136</td>\n",
       "      <td>122</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>121</td>\n",
       "      <td>241</td>\n",
       "      <td>154</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>221</td>\n",
       "      <td>122</td>\n",
       "      <td>156</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>163</td>\n",
       "      <td>150</td>\n",
       "      <td>184</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0       0    1    2    3\n",
       "CATEGORY                    \n",
       "b         209  136  122  266\n",
       "e         121  241  154  227\n",
       "m         221  122  156  260\n",
       "t         163  150  184  268"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will use the same number of k clusters.\n",
    "minibatchkmeans = MiniBatchKMeans(n_clusters=4, init='k-means++', random_state=42)\n",
    "y_pred2 = minibatchkmeans.fit_predict(X2_train)\n",
    "\n",
    "pd.crosstab(y2_train, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Score: 0.009429119729525967\n",
      "Silhouette Score: 0.22255351693037823\n"
     ]
    }
   ],
   "source": [
    "# Displaying adjusted rand index and silhouette coefficient.\n",
    "print('Adjusted Rand Score: {}'.format(adjusted_rand_score(y2_train, y_pred2)))\n",
    "print('Silhouette Score: {}'.format(silhouette_score(X2_train, y_pred2, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mini Batch K-Means clustering model is slightly worse than K-Means clustering across both scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral clustering (and affinity propagation, which I will use next) is based on quantifying similarity between data points, such as words that often appear in the same context would all be types of \"similarity\" potentially detectable by these algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CATEGORY</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>154</td>\n",
       "      <td>340</td>\n",
       "      <td>76</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>126</td>\n",
       "      <td>344</td>\n",
       "      <td>54</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>167</td>\n",
       "      <td>353</td>\n",
       "      <td>73</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>149</td>\n",
       "      <td>382</td>\n",
       "      <td>56</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0       0    1   2    3\n",
       "CATEGORY                   \n",
       "b         154  340  76  163\n",
       "e         126  344  54  219\n",
       "m         167  353  73  166\n",
       "t         149  382  56  178"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keeping consistency with number of clusters since we know we're looking for four clusters.\n",
    "n_clusters= 4\n",
    "\n",
    "# Declare and fit the model.\n",
    "sc = SpectralClustering(n_clusters=n_clusters)\n",
    "y_pred3 = sc.fit_predict(X2_train)\n",
    "\n",
    "pd.crosstab(y2_train, y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Score: 0.0014068616971487622\n",
      "Silhouette Score: 0.02310685574815792\n"
     ]
    }
   ],
   "source": [
    "# Displaying adjusted rand index and silhouette coefficient.\n",
    "print('Adjusted Rand Score: {}'.format(adjusted_rand_score(y2_train, y_pred3)))\n",
    "print('Silhouette Score: {}'.format(silhouette_score(X2_train, y_pred3, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Spectral clustering model is only slightly better than the K-Means clustering solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted, I am going to attempt one more clustering model, Affinity Propogation.\n",
    "\n",
    "Affinity Propagation is based on defining exemplars for data points. An exemplar is a data point similar enough to another data point that one could conceivably be represented by the other  they convey largely the same information. Affinity Propagation chooses the number of clusters based on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Number of estimated clusters: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CATEGORY</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows  100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     0   1   2   3   4   5   6   7   8   9  ...  90  91  92  93  94  95  \\\n",
       "CATEGORY                                         ...                           \n",
       "b          6  13   9   6   0   9   8  12  11   7 ...   3  16   7   6   2   9   \n",
       "e         10   8   7   4  11   9   4   5   6  12 ...   5   7  13  11   7   6   \n",
       "m          4  17  10   2   2  12   6  10   9   3 ...   5   9   6   4   2   7   \n",
       "t          8  13   8   7   6  13   7   7   9   5 ...   2   5  10   7   5  11   \n",
       "\n",
       "col_0     96  97  98  99  \n",
       "CATEGORY                  \n",
       "b          1  11   3   5  \n",
       "e          3   7   2   1  \n",
       "m          2  11   3   4  \n",
       "t          0   8   1   4  \n",
       "\n",
       "[4 rows x 100 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare and fit the model. Note, you can provide arguments to the model but I have chosen not to.\n",
    "af = AffinityPropagation()\n",
    "y_pred4 = af.fit_predict(X2_train)\n",
    "print('Done')\n",
    "\n",
    "# Pull the number of clusters and cluster assignments for each data point.\n",
    "cluster_centers_indices = af.cluster_centers_indices_\n",
    "n_clusters = len(cluster_centers_indices)\n",
    "labels = af.labels_\n",
    "\n",
    "print('Number of estimated clusters: {}'.format(n_clusters))\n",
    "\n",
    "pd.crosstab(y2_train, y_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Score: 0.0007045026862398638\n",
      "Silhouette Score: 0.14098292111773575\n"
     ]
    }
   ],
   "source": [
    "# Displaying adjusted rand index and silhouette coefficient.\n",
    "print('Adjusted Rand Score: {}'.format(adjusted_rand_score(y2_train, y_pred4)))\n",
    "print('Silhouette Score: {}'.format(silhouette_score(X2_train, y_pred4, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Affinity Propogation model is the worst performing of all the clustering model solutions. This model is terribly overfit as well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the clustering model solutions attempted (K-Means, Mini Batch K-Means, Spectral and Affinity Propogation) performed poorly in terms of idenifying/predicting the cateogry of a news article (business, science and technology, entertainment, health) given only its headline.\n",
    "\n",
    "This could be due to  perhaps the headlines alone do not offer enough to distinguish between the different categories. We could look for improvement by using parts of the text from the body of the article, such as the first paragraph.\n",
    "\n",
    "Of all the models attempted, K-Means performed the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Including K-Means clustering predictions as feature in our training set for Supervised Learning.\n",
    "X2_train_cluster = pd.DataFrame(X2_train)\n",
    "X2_train_cluster['kmeans_cluster'] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest can be used for both classification and regression problems. As a classifier the most popular outcome (the mode) is returned. Instead of making one decision tree you make several and each tree in the forest gets a vote on the outcome for a given observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set score without clustering: 0.6206722025361257\n"
     ]
    }
   ],
   "source": [
    "# Standard Random Forest Classifier.\n",
    "rfc = RandomForestClassifier()\n",
    "train = rfc.fit(X2_train, y2_train)\n",
    "rfc_scores = cross_val_score(rfc, X2_train, y_train, cv=5)\n",
    "\n",
    "print('\\nTraining set score without clustering: {}'.format(rfc_scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score with clustering: 0.6263655990646054\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier with clustering.\n",
    "rfc_cluster = RandomForestClassifier()\n",
    "train_cluster = rfc_cluster.fit(X2_train_cluster, y2_train)\n",
    "rfc_cluster_scores = cross_val_score(rfc_cluster, X2_train_cluster, y_train, cv=5)\n",
    "\n",
    "print('Training set score with clustering: {}'.format(rfc_cluster_scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest Classifier solution with clustering performed best, by a small margin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our outcome is categorical rather than continuous and we are interested in predicting the probability of an outcome, I am going to use Logistic Regression as a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set score without clustering: 0.734989367909894\n"
     ]
    }
   ],
   "source": [
    "# Standard Logistic Regression classifier.\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X2_train, y2_train)\n",
    "lr_scores = cross_val_score(lr, X2_train, y_train, cv=5)\n",
    "\n",
    "print('\\nTraining set score without clustering: {}'.format(lr_scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score with clustering: 0.7339926956876255\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression classifier with clustering.\n",
    "lr_cluster = LogisticRegression()\n",
    "train_cluster = lr_cluster.fit(X2_train_cluster, y2_train)\n",
    "lr_cluster_scores = cross_val_score(lr_cluster, X2_train_cluster, y_train, cv=5)\n",
    "\n",
    "print('Training set score with clustering: {}'.format(lr_cluster_scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Logistic Regression classifier without clustering performed best, but again by a small margin. Although, the Logistic Regression solutions both performed better than each of their Random Forest counterparts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosting can work on any combination of loss function and model type, as long as we can calculate the derivatives of the loss function with respect to the model parameters. Most often, however, gradient boosting uses decision trees, and minimizes either the residual (regression trees) or the negative log-likelihood (classification trees). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set score without clustering: 0.7040098095404408\n"
     ]
    }
   ],
   "source": [
    "# Standard Gradient Boosting classifier.\n",
    "clf = GradientBoostingClassifier()\n",
    "train = clf.fit(X2_train, y2_train)\n",
    "clf_scores = cross_val_score(clf, X2_train, y_train, cv=5)\n",
    "\n",
    "print('\\nTraining set score without clustering: {}'.format(clf_scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score with clustering: 0.7046698169479307\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting classifier with clustering.\n",
    "clf_cluster = GradientBoostingClassifier()\n",
    "train_cluster = clf_cluster.fit(X2_train_cluster, y2_train)\n",
    "clf_cluster_scores = cross_val_score(clf_cluster, X2_train_cluster, y_train, cv=5)\n",
    "\n",
    "print('Training set score with clustering: {}'.format(clf_cluster_scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gradient Boosting classifier with clustering performed best, but only by the slightest margin once again. Each Gradient Boosting classifer produced a lower accuracy score than it's Logistic Regression counterparts. But it did outperform both types of Random Forest classifiers, which I expected as in many cases gradient boosted decision trees perform better than random forests.\n",
    "\n",
    "In the end, amongst the Supervised Learning classification solutions, Logistic Regression performed the best. Now I will pivot from the training sets to the test sets using the model that performed best within all of Supervised and Unsupervised solutions attempted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data.\n",
    "X_test_norm = normalize(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scanning each row for tokens. Also capturing the length of each heading and identifying the different parts of speech.\n",
    "X_test_words = []\n",
    "\n",
    "for row in X_test:\n",
    "    row_doc = nlp(row)\n",
    "    heading_len = len(row_doc) \n",
    "    advs = 0\n",
    "    verb = 0\n",
    "    noun = 0\n",
    "    adj = 0\n",
    "    for token in row_doc:\n",
    "        if token.pos_ == 'ADV':\n",
    "            advs +=1\n",
    "        elif token.pos_ == 'VERB':\n",
    "            verb +=1\n",
    "        elif token.pos_ == 'NOUN':\n",
    "            noun +=1\n",
    "        elif token.pos_ == 'ADJ':\n",
    "            adj +=1\n",
    "\n",
    "    X_test_words.append([row_doc, advs, verb, noun, adj, heading_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_new = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturing generated features in new dataframe with categories.\n",
    "news_bow_test = pd.DataFrame(data=X_test_words, columns=['BOW', 'ADV', 'VERB', 'NOUN', 'ADJ', 'heading_length'])\n",
    "\n",
    "news_bow_test = pd.concat([news_bow_test, y_test_new], ignore_index=False, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOW</th>\n",
       "      <th>ADV</th>\n",
       "      <th>VERB</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>heading_length</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(kaepernick, denies, wrongdoing, details, star...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(apple, agrees, to, conditional, million, eboo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(canadian, stocks, tumble, for, second, day, a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(today, in, apis, instagram, looking, to, repl...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(half, of, us, adults, eligible, for, statins,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 BOW  ADV  VERB  NOUN  ADJ  \\\n",
       "0  (kaepernick, denies, wrongdoing, details, star...    0     3     5    0   \n",
       "1  (apple, agrees, to, conditional, million, eboo...    0     1     3    2   \n",
       "2  (canadian, stocks, tumble, for, second, day, a...    0     1     3    2   \n",
       "3  (today, in, apis, instagram, looking, to, repl...    0     2     4    3   \n",
       "4  (half, of, us, adults, eligible, for, statins,...    0     0     6    1   \n",
       "\n",
       "   heading_length CATEGORY  \n",
       "0              10        b  \n",
       "1               8        t  \n",
       "2              11        b  \n",
       "3              12        t  \n",
       "4              11        m  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_bow_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOW</th>\n",
       "      <th>ADV</th>\n",
       "      <th>VERB</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>heading_length</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>(a, blood, test, that, can, predict, alzheimer...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>(new, home, sales, on, the, rise)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>(fashion, disaster, kim, kardashian, flaunts, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>(burger, king, 's, gay, pride, whopper, photo,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>(the, hilarious, apple, song, you, need, to, h...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   BOW  ADV  VERB  NOUN  ADJ  \\\n",
       "995  (a, blood, test, that, can, predict, alzheimer...    0     2     4    1   \n",
       "996                  (new, home, sales, on, the, rise)    0     0     3    1   \n",
       "997  (fashion, disaster, kim, kardashian, flaunts, ...    0     1     5    1   \n",
       "998  (burger, king, 's, gay, pride, whopper, photo,...    0     0     8    0   \n",
       "999  (the, hilarious, apple, song, you, need, to, h...    0     2     3    1   \n",
       "\n",
       "     heading_length CATEGORY  \n",
       "995              10        m  \n",
       "996               6        b  \n",
       "997              12        e  \n",
       "998              10        b  \n",
       "999               9        t  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_bow_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Including the Tf-idf vectors created earlier.\n",
    "X_test_norm_df = pd.DataFrame(data=X_test_norm.toarray())\n",
    "news_tfidf_bow_test = pd.concat([news_bow_test, X_test_norm_df], ignore_index=False, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOW</th>\n",
       "      <th>ADV</th>\n",
       "      <th>VERB</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>heading_length</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>3673</th>\n",
       "      <th>3674</th>\n",
       "      <th>3675</th>\n",
       "      <th>3676</th>\n",
       "      <th>3677</th>\n",
       "      <th>3678</th>\n",
       "      <th>3679</th>\n",
       "      <th>3680</th>\n",
       "      <th>3681</th>\n",
       "      <th>3682</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(kaepernick, denies, wrongdoing, details, star...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(apple, agrees, to, conditional, million, eboo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>t</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(canadian, stocks, tumble, for, second, day, a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(today, in, apis, instagram, looking, to, repl...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>t</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(half, of, us, adults, eligible, for, statins,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  3690 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 BOW  ADV  VERB  NOUN  ADJ  \\\n",
       "0  (kaepernick, denies, wrongdoing, details, star...    0     3     5    0   \n",
       "1  (apple, agrees, to, conditional, million, eboo...    0     1     3    2   \n",
       "2  (canadian, stocks, tumble, for, second, day, a...    0     1     3    2   \n",
       "3  (today, in, apis, instagram, looking, to, repl...    0     2     4    3   \n",
       "4  (half, of, us, adults, eligible, for, statins,...    0     0     6    1   \n",
       "\n",
       "   heading_length CATEGORY    0    1    2  ...   3673  3674  3675  3676  3677  \\\n",
       "0              10        b  0.0  0.0  0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "1               8        t  0.0  0.0  0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "2              11        b  0.0  0.0  0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "3              12        t  0.0  0.0  0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "4              11        m  0.0  0.0  0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   3678  3679  3680  3681  3682  \n",
       "0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 3690 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_tfidf_bow_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOW</th>\n",
       "      <th>ADV</th>\n",
       "      <th>VERB</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>heading_length</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>3673</th>\n",
       "      <th>3674</th>\n",
       "      <th>3675</th>\n",
       "      <th>3676</th>\n",
       "      <th>3677</th>\n",
       "      <th>3678</th>\n",
       "      <th>3679</th>\n",
       "      <th>3680</th>\n",
       "      <th>3681</th>\n",
       "      <th>3682</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>(a, blood, test, that, can, predict, alzheimer...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>(new, home, sales, on, the, rise)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>(fashion, disaster, kim, kardashian, flaunts, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>(burger, king, 's, gay, pride, whopper, photo,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>(the, hilarious, apple, song, you, need, to, h...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>t</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  3690 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   BOW  ADV  VERB  NOUN  ADJ  \\\n",
       "995  (a, blood, test, that, can, predict, alzheimer...    0     2     4    1   \n",
       "996                  (new, home, sales, on, the, rise)    0     0     3    1   \n",
       "997  (fashion, disaster, kim, kardashian, flaunts, ...    0     1     5    1   \n",
       "998  (burger, king, 's, gay, pride, whopper, photo,...    0     0     8    0   \n",
       "999  (the, hilarious, apple, song, you, need, to, h...    0     2     3    1   \n",
       "\n",
       "     heading_length CATEGORY    0    1    2  ...   3673  3674  3675  3676  \\\n",
       "995              10        m  0.0  0.0  0.0  ...    0.0   0.0   0.0   0.0   \n",
       "996               6        b  0.0  0.0  0.0  ...    0.0   0.0   0.0   0.0   \n",
       "997              12        e  0.0  0.0  0.0  ...    0.0   0.0   0.0   0.0   \n",
       "998              10        b  0.0  0.0  0.0  ...    0.0   0.0   0.0   0.0   \n",
       "999               9        t  0.0  0.0  0.0  ...    0.0   0.0   0.0   0.0   \n",
       "\n",
       "     3677  3678  3679  3680  3681  3682  \n",
       "995   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "996   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "997   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "998   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "999   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 3690 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_tfidf_bow_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection.\n",
    "features_test = news_tfidf_bow_test.drop(['BOW', 'CATEGORY'], axis=1)\n",
    "\n",
    "# Categories.\n",
    "y2_test = news_tfidf_bow_test.CATEGORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As before, using k best with chi-squared to select the 400 best features.\n",
    "kbest_test = SelectKBest(chi2, k=400)\n",
    "\n",
    "X2_test = kbest_test.fit_transform(features_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CATEGORY</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>82</td>\n",
       "      <td>56</td>\n",
       "      <td>95</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>77</td>\n",
       "      <td>45</td>\n",
       "      <td>72</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>80</td>\n",
       "      <td>35</td>\n",
       "      <td>97</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>87</td>\n",
       "      <td>45</td>\n",
       "      <td>83</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0      0   1   2   3\n",
       "CATEGORY                \n",
       "b         82  56  95  34\n",
       "e         77  45  72  63\n",
       "m         80  35  97  29\n",
       "t         87  45  83  20"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-Means clustering on test set with 4 clusters.\n",
    "kmeans_test = KMeans(n_clusters=4, init='k-means++', random_state=42)\n",
    "y_pred_test = kmeans_test.fit_predict(X2_test)\n",
    "\n",
    "pd.crosstab(y2_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Score: 0.0051089547521292605\n",
      "Silhouette Score: 0.274217861996886\n"
     ]
    }
   ],
   "source": [
    "# Displaying adjusted rand index and silhouette coefficient.\n",
    "print('Adjusted Rand Score: {}'.format(adjusted_rand_score(y2_test, y_pred_test)))\n",
    "print('Silhouette Score: {}'.format(silhouette_score(X2_test, y_pred_test, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Adjusted Rand Score fell by 0.004 using the test set while the Silhouette score improved by 0.05 nearly. Clustering within the train set was primarily evenly distributed between cluster 1, 2 and 3 with cluster 0 falling a bit behind. Within the test set, it seems clustering is relatively even distributed between clusters 0 and 2 while clusters 1 and 3 fall behind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing set score without clustering: 0.6479458521116493\n"
     ]
    }
   ],
   "source": [
    "# Standard Logistic Regression classifier on test set.\n",
    "lr_test = LogisticRegression()\n",
    "train_test = lr.fit(X2_test, y2_test)\n",
    "lr_scores_test = cross_val_score(lr_test, X2_test, y_test, cv=5)\n",
    "\n",
    "print('\\nTesting set score without clustering: {}'.format(lr_scores_test.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard Logistic Regression classifier significantly underperformed with the test set as compared to the train set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion ...\n",
    "\n",
    "As noted or showcased throughout this notebook, the classification of articles into their respective categories by using the headline only has proven to be difficult and unreliable. I started with attempting different clustering methods, such as K-Means, Mini Batch K-Means, Spectral and Affinity Propogation, but all four performed poorly. From there, I switched my approach to attempting different supervised learning classifiers, such as Random Forest, Logistic Regression and Gradient Boosting. Logistic Regression was the best performer and showed some promise but still left significant opportunity for improvement.\n",
    "\n",
    "The challenge with attempting to classify articles into categories based on headers alone may be due to the lack of text within the headings themselves. Headlines, as in their very nature, are meant to be short, quick attemtps to grab your attention and hopefully get you to read the underlying article. I suggested earlier that one could expect to have more success in their attempt if they were able to pull a certain amount of text from the body of the article itself. Piggybacking off my initial statement about the lack of text, there could be a lack of diversity in the headlines as well although I find that to be less practical."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
